{"meta":{"title":"BuT的博客","subtitle":"不要因为路远而不走 只有走就能走得到 不要因为石重而不搬 只要搬就能搬得动","description":"","author":"BuT","url":"http://bigtrex.top","root":"/"},"pages":[{"title":"标签","text":"","path":"tags/index.html","date":"07-28","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"07-27","excerpt":""}],"posts":[{"title":"关于MD锚点的坑","text":"关于MD锚点的坑锚点是一个方便定位的东西，用起来还是很香的 但是不同MarkDown对锚点的解释都有些许区别，导致不同平台上锚点可能会失效 MarkDown中对于锚点的语法定义如下： 12345[描述](#定位的title)...# 定位的Title 多级标题都可以作为’定位的title’，另外标题中大写字母会自动转为小写字母 For Example … … … … … For Example这样的锚点在vscode这样的编辑器上是没有问题的，但是放到如github，csdn上会失效 代码如下： 123[For Example](#for-example)## For Example 对于hexo+github搭建的博客，这样的锚点失效在于#后的内容和标题不一致，主要在于英文大小写，中文不存在如上问题 修改为如下的代码，在hexo+github上可以实现锚点，然而对于vscode这样的编辑器当然失效了，另外这样的锚点在csdn上也会失效 123[For Example2](#For-Example2)## For Example2 For Example2 … … … … … For Example2目前来看纯MarkDown语法的锚点总会存在一些坑，一个通用解决方法是配合html中锚点的使用，代码如下： 123[点击跳转到For Example3](#Test)&lt;a id=&quot;Test&quot;&gt;For Example3&lt;/a&gt; 其中id值只支持英文，id值和#后的值完全一致，不支持id值包含空格 当然，这样的代码并非按照MarkDown的思想直接将标题作为锚点的定位点，但是这样的锚点在vscode，github，csdn上都可以work！ 点击跳转到For Example3 … … … … … … … For Example3 … … … … …","path":"关于MD锚点的坑/","date":"08-04","excerpt":"","tags":[]},{"title":"Python正则表达式自查","text":"Python正则表达式自查 正则表达式是一种针对字符串表达“简洁”和“特征”思想的工具 正则表达式可以用来判断某字符串的特征归属 正则表达式语法由字符和操作符构成 1. Python正则表达式使用 2. Python正则表达式语法 3. Regex库方法 4. Match对象 5. 贪婪匹配和最小匹配 6. 实例 python正则表达式使用1234567891011121314import re# 不需要对转义符进行转义的原生字符串类型，直接表达一个正则表达式r&#x27;text&#x27; # 两种用法rst = re.search(r&#x27;[1‐9]\\d&#123;5&#125;&#x27;, &#x27;BIT 100081&#x27;)# compile方法可以使用原生字符串或字符串pat = re.compile(r&#x27;[1‐9]\\d&#123;5&#125;&#x27;)rst = pat.search(&#x27;BIT 100081&#x27;)if rst: print(rst.group(0)) python正则表达式语法1234567891011121314. 表示任何单个字符[] 对**单个字符**给出取值范围[^] 对**单个字符**给出排除范围* *前字符重复0~无限次+ +前字符重复1~无限次? ?前字符重复0~1次| 左右表达式任意一个&#123;m&#125; 对前一个字符重复m次&#123;m,n&#125; 对前一个字符重复[m,n]次，&#123;:3&#125;表示[0,3]次^ 匹配字符串开头$ 匹配字符串结尾() 分组标记，内部只能使用|操作符\\d 表示数字字符，等价于[0-9]\\w 表示单词字符，等价于[A-Za-z0-9_] regex库方法 re.search(pattern, string, flags&#x3D;0)在字符串中搜索匹配的第一个位置，返回match对象 re.match(pattern, string, flags&#x3D;0)从字符串开始位置起匹配正则表达式，返回match对象 re.findall(pattern, string, flags&#x3D;0)匹配所有的子串，返回列表 re.split(pattern, string, maxsplit&#x3D;0, flags&#x3D;0)将字符串按照正则表达式子串进行分割，返回列表 re.finditer(pattern, string, flags&#x3D;0)返回匹配的迭代类型，返回match对象 re.sub(pattern, repl, string, count&#x3D;0, flags&#x3D;0)在字符串中替换所有匹配子串，返回字符串 参数含义： 参数 含义 pattern 正则表达式的字符串或原生字符串表示 string 待匹配字符串 flags 正则表达式使用时的控制标记 maxsplit 最大分割数，剩余部分作为最后一个元素输出 repl 替换匹配字符串的字符串 count 最大替换次数 控制标记含义： 控制标记 含义 re.I re.IGNORECASE 忽略正则表达式的大小写，[A‐Z]能够匹配小写字符 re.M re.MULTILINE 正则表达式中的^操作符能够将给定字符串的每行当作匹配开始 re.S re.DOTALL 正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符 match对象Match对象是一次匹配的结果，包含匹配的所有信息 .string 待匹配的字符串 .re 用于匹配的正则表达式 .pos 搜索的开始位置 .endpos 搜索的结束位置 .group(0) 匹配的子串 .start() 匹配子串在字符串中的开始位置 .end() 匹配子串在字符串中的结束位置 .span() 返回(.start(), .end()) 贪婪匹配和最小匹配对于同一个匹配子串开始位置，可能存在多个结束位置满足匹配： Re库默认采用贪婪匹配，即输出匹配最长的子串 通过在操作符后增加?变成最小匹配 *? 前一个字符重复0~无限次，最小匹配 +? 前一个字符重复1~无限次，最小匹配 ?? 前一个字符重复0~1次，最小匹配 {m,n}? 前一个字符重复[m,n]次，最小匹配 实例12345[\\u4e00‐\\u9fa5] 匹配中文字符^[A‐Za‐z]+$ 由26个字母组成的字符串^‐?\\d+$ 整数^[0‐9]*[1‐9][0‐9]*$ 正整数(([1‐9]?\\d|1\\d&#123;2&#125;|2[0‐4]\\d|25[0‐5]).)&#123;3&#125;([1‐9]?\\d|1\\d&#123;2&#125;|2[0‐4]\\d|25[0‐5]) 匹配IPv4地址","path":"Python正则表达式自查/","date":"08-03","excerpt":"","tags":[]},{"title":"爬虫学习记录","text":"爬虫学习记录 使用python第三方库requests库进行网页爬取 get方法 post方法 Fn12利用浏览器抓包工具分析 User-Agent Content-Type 获取网页真正请求的url 查看网页提交请求的方法 Ajax数据分析 Asynchronous JavaScript and XML（异步的 JavaScript 和 XML） 页面局部刷新 利用爬虫爬取数据的第一步是分析页面 XML XML Extensiable Markup Language 可扩展标记语言 html -&gt; xhtml -&gt; xml Ajax基于XML实现 json模块 requests库的Response对象的json()方法返回一个json对象，类型为字典 json模块提供了4个方便的方法编码和解析json数据 json.dumps() -&gt; 将Python数据转换为json格式数据 jsom.loads() -&gt; 将json编码的字符串转换为一个Python数据结构 json.dump() -&gt; 用于文件 json.load() -&gt; 用于文件 json数据格式化工具 Python正则表达式 进行数据解析从而实现聚焦爬虫 动态加载数据在对一个url发起请求时，页面中的数据可能由动态加载得到，重新对该url提交请求在抓包工具中查看对应url数据包，进一步判断请求得到的数据是否包含页面中的某些数据 判断网页是否采用AJax利用爬虫爬取网页数据时，首先需要分析数据到底是在服务器端组成好发回给浏览器的？还是通过AJax请求异步发送的？ AJax请求数据包在XHR选项中 利用AJax时，网页变化时url往往不会发生变化 对于一个AJax请求，会额外返回一个X-Requested-With: XMLHttpRequest头部字段，一个普通的请求没有该字段","path":"爬虫学习记录/","date":"08-01","excerpt":"","tags":[]},{"title":"反反爬","text":"反反爬总结1. 百度安全验证 2. 某数反爬 百度安全验证通常修改request的请求头载体模拟时，使用浏览器的User-Agent字段： 1Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36 Edg/103.0.1264.77 可能遭遇百度反爬拦截，自动跳转到百度安全验证 常用解决方案： 修改UA字段 增加更多头信息，例如Accept-Language 某数反爬在练习爬取化妆品生产许可信息管理服务平台时遇到HTTP状态码400，打开网络检查工具会直接跳转到源代码，一种说法是陷入无限debug中（每次返回的js代码不同），也无法添加断点，该站通过AJax请求更新页面时，提交的url携带两个随机生成的参数，无法通过后端的参数验证，暂时无法破解 一些某数逆向方法 使用fiddler进行请求拦截，进行调试 使用chrome的script监听器进行调试 本地搭建环境","path":"反反爬/","date":"08-01","excerpt":"","tags":[]},{"title":"本地图片","text":"","path":"本地图片/","date":"07-30","excerpt":"","tags":[]},{"title":"MD语法自查","text":"MarkDown语法自查1. 标题 2. 列表 3. 字体 4. 锚点 5. 代码块 6. 图片和超链接 7. 表格 8. 引用 标题主标题副标题一级标题二级标题六级标题列表有序列表： 首先 首先 首首先 其其次 最最后 其次 最后 其次 最后 无序列表： 首先 首先 其次 最后 其次 最后 字体斜体 粗体 粗斜体 花裙子 删除线 删除线 锚点定位到这里 代码块1234int main()&#123; return 0;&#125; 12def func(age): return age int a=5+9; 图片和超链接 csdn社区 https://www.csdn.net/ 表格 姓名 年龄 职业 张三 20000 医生 李四 60 警察叔叔 引用张三说： 阿门阿前一棵葡萄树 葡萄树说：这是不对的","path":"MD语法自查/","date":"07-29","excerpt":"","tags":[]},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","path":"hello-world/","date":"07-17","excerpt":"","tags":[]}],"categories":[],"tags":[]}