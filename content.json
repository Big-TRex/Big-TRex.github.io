{"meta":{"title":"BuT的博客","subtitle":"不要因为路远而不走 只有走就能走得到 不要因为石重而不搬 只要搬就能搬得动","description":"","author":"BuT","url":"http://bigtrex.top","root":"/"},"pages":[{"title":"标签","text":"","path":"tags/index.html","date":"07-28","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"07-27","excerpt":""}],"posts":[{"title":"bs4方法自查","text":"bs4库方法自查Beautiful Soup库是解析、遍历、维护“标签树”的功能库 BeautifulSoup使用方法123456from bs4 import BeautifulSoupimport bs4soup=BeautifulSoup(&lt;html&gt;response.text&lt;/html&gt;,&#x27;html.parser&#x27;)soup=BeautifulSoup(open(&#x27;*.html&#x27;,&#x27;r&#x27;),&#x27;html.parser&#x27;) BeautifulSoup类基本元素 基本元素 含义 Tag 标签，以&lt;&gt;…&lt;&#x2F;&gt;组成 Name 标签名，&lt;p&gt;…&lt;&#x2F;p&gt;的名字是p：&lt;tag&gt;.name Attributes 标签的属性，字典形式组织：.attrs NavigableString 标签内非属性字符串，标签下只能有一个子节点：.string，返回NavigableString text 标签内字符串，可跨域层级：.text，返回str Comment 标签内字符串的注释部分：.string text和string的区别 BeautifulSoup类常用方法一篇总结bs4非常相近且准确的blog bs4方法详情","path":"bs4方法自查/","date":"08-05","excerpt":"","tags":[]},{"title":"爬虫中文乱码","text":"爬虫中文乱码","path":"爬虫中文乱码/","date":"08-05","excerpt":"","tags":[]},{"title":"关于MD锚点的坑","text":"关于MD锚点的坑锚点是一个方便定位的东西，用起来还是很香的 但是不同MarkDown对锚点的解释都有些许区别，导致不同平台上锚点可能会失效 MarkDown中对于锚点的语法定义如下： 12345[描述](#定位的title)...# 定位的Title 多级标题都可以作为’定位的title’，另外标题中大写字母会自动转为小写字母 For Example … … … … … For Example这样的锚点在vscode这样的编辑器上是没有问题的，但是放到如github，csdn上会失效 代码如下： 123[For Example](#for-example)## For Example 对于hexo+github搭建的博客，这样的锚点失效在于#后的内容和标题不一致，主要在于英文大小写，中文不存在如上问题 修改为如下的代码，在hexo+github上可以实现锚点，然而对于vscode这样的编辑器当然失效了，另外这样的锚点在csdn上也会失效 123[For Example2](#For-Example2)## For Example2 For Example2 … … … … … For Example2目前来看纯MarkDown语法的锚点总会存在一些坑，一个通用解决方法是配合html中锚点的使用，代码如下： 123[点击跳转到For Example3](#Test)&lt;a id=&quot;Test&quot;&gt;For Example3&lt;/a&gt; 其中id值只支持英文，id值和#后的值完全一致，不支持id值包含空格 当然，这样的代码并非按照MarkDown的思想直接将标题作为锚点的定位点，但是这样的锚点在vscode，github，csdn上都可以work！ 点击跳转到For Example3 … … … … … … … For Example3 … … … … …","path":"关于MD锚点的坑/","date":"08-04","excerpt":"","tags":[]},{"title":"Python正则表达式自查","text":"Python正则表达式自查 正则表达式是一种针对字符串表达“简洁”和“特征”思想的工具 正则表达式可以用来判断某字符串的特征归属 正则表达式语法由字符和操作符构成 1. Python正则表达式使用 2. Python正则表达式语法 3. Regex库方法 4. Match对象 5. 贪婪匹配和最小匹配 6. 实例 python正则表达式使用1234567891011121314import re# 不需要对转义符进行转义的原生字符串类型，直接表达一个正则表达式r&#x27;text&#x27; # 两种用法rst = re.search(r&#x27;[1‐9]\\d&#123;5&#125;&#x27;, &#x27;BIT 100081&#x27;)# compile方法可以使用原生字符串或字符串pat = re.compile(r&#x27;[1‐9]\\d&#123;5&#125;&#x27;)rst = pat.search(&#x27;BIT 100081&#x27;)if rst: print(rst.group(0)) python正则表达式语法1234567891011121314. 表示任何单个字符[] 对**单个字符**给出取值范围[^] 对**单个字符**给出排除范围* *前字符重复0~无限次+ +前字符重复1~无限次? ?前字符重复0~1次| 左右表达式任意一个&#123;m&#125; 对前一个字符重复m次&#123;m,n&#125; 对前一个字符重复[m,n]次，&#123;:3&#125;表示[0,3]次^ 匹配字符串开头$ 匹配字符串结尾() 分组标记，内部只能使用|操作符\\d 表示数字字符，等价于[0-9]\\w 表示单词字符，等价于[A-Za-z0-9_] regex库方法 re.search(pattern, string, flags&#x3D;0)在字符串中搜索匹配的第一个位置，返回match对象 re.match(pattern, string, flags&#x3D;0)从字符串开始位置起匹配正则表达式，返回match对象 re.findall(pattern, string, flags&#x3D;0)匹配所有的子串，返回列表 re.split(pattern, string, maxsplit&#x3D;0, flags&#x3D;0)将字符串按照正则表达式子串进行分割，返回列表 re.finditer(pattern, string, flags&#x3D;0)返回匹配的迭代类型，返回match对象 re.sub(pattern, repl, string, count&#x3D;0, flags&#x3D;0)在字符串中替换所有匹配子串，返回字符串 参数含义： 参数 含义 pattern 正则表达式的字符串或原生字符串表示 string 待匹配字符串 flags 正则表达式使用时的控制标记 maxsplit 最大分割数，剩余部分作为最后一个元素输出 repl 替换匹配字符串的字符串 count 最大替换次数 控制标记含义： 控制标记 含义 re.I re.IGNORECASE 忽略正则表达式的大小写，[A‐Z]能够匹配小写字符 re.M re.MULTILINE 正则表达式中的^操作符能够将给定字符串的每行当作匹配开始 re.S re.DOTALL 正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符 match对象Match对象是一次匹配的结果，包含匹配的所有信息 .string 待匹配的字符串 .re 用于匹配的正则表达式 .pos 搜索的开始位置 .endpos 搜索的结束位置 .group(0) 匹配的子串 .start() 匹配子串在字符串中的开始位置 .end() 匹配子串在字符串中的结束位置 .span() 返回(.start(), .end()) 贪婪匹配和最小匹配对于同一个匹配子串开始位置，可能存在多个结束位置满足匹配： Re库默认采用贪婪匹配，即输出匹配最长的子串 通过在操作符后增加?变成最小匹配 *? 前一个字符重复0~无限次，最小匹配 +? 前一个字符重复1~无限次，最小匹配 ?? 前一个字符重复0~1次，最小匹配 {m,n}? 前一个字符重复[m,n]次，最小匹配 实例12345[\\u4e00‐\\u9fa5] 匹配中文字符^[A‐Za‐z]+$ 由26个字母组成的字符串^‐?\\d+$ 整数^[0‐9]*[1‐9][0‐9]*$ 正整数(([1‐9]?\\d|1\\d&#123;2&#125;|2[0‐4]\\d|25[0‐5]).)&#123;3&#125;([1‐9]?\\d|1\\d&#123;2&#125;|2[0‐4]\\d|25[0‐5]) 匹配IPv4地址","path":"Python正则表达式自查/","date":"08-03","excerpt":"","tags":[]},{"title":"爬虫学习记录","text":"爬虫学习记录 使用python第三方库requests库进行网页爬取 get方法 post方法 Fn12利用浏览器抓包工具分析 User-Agent Content-Type 获取网页真正请求的url 查看网页提交请求的方法 Ajax数据分析 Asynchronous JavaScript and XML（异步的 JavaScript 和 XML） 页面局部刷新 利用爬虫爬取数据的第一步是分析页面 XML XML Extensiable Markup Language 可扩展标记语言 html -&gt; xhtml -&gt; xml Ajax基于XML实现 json模块(JavsScript Object Notation)一种信息标记格式规范 requests库的Response对象的json()方法返回一个json对象，类型为字典 json模块提供了4个方便的方法编码和解析json数据 json.dumps() -&gt; 将Python数据转换为json格式数据 jsom.loads() -&gt; 将json编码的字符串转换为一个Python数据结构 json.dump() -&gt; 用于文件 json.load() -&gt; 用于文件 json数据格式化工具 Python正则表达式 进行数据解析从而实现聚焦爬虫 bs4库 bs4是Python独有的一种解析数据方式 基于其它语言的爬虫不支持bs4 xpath库 xpath是通用的用于解析HTML数据的库 xpath的语法简洁，但是容易出现返回空列表问题 验证码和打码 base64数据编码 用于将 动态加载数据在对一个url发起请求时，页面中的数据可能由动态加载得到，重新对该url提交请求在抓包工具中查看对应url数据包，进一步判断请求得到的数据是否包含页面中的某些数据 判断网页是否采用AJax利用爬虫爬取网页数据时，首先需要分析数据到底是在服务器端组成好发回给浏览器的？还是通过AJax请求异步发送的？ AJax请求数据包在XHR选项中 利用AJax时，网页变化时url往往不会发生变化 对于一个AJax请求，会额外返回一个X-Requested-With: XMLHttpRequest头部字段，一个普通的请求没有该字段","path":"爬虫学习记录/","date":"08-01","excerpt":"","tags":[]},{"title":"反反爬","text":"反反爬总结1. 百度安全验证 2. 某数反爬 3. 验证码 4. 隐藏域 5. 封ip 6. ajax携带随机参数 7. 伪url 百度安全验证通常修改request的请求头载体模拟时，使用浏览器的User-Agent字段： 1Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36 Edg/103.0.1264.77 可能遭遇百度反爬拦截，自动跳转到百度安全验证 常用解决方案： 修改UA字段 增加更多头信息，例如Accept-Language 某数反爬在练习爬取化妆品生产许可信息管理服务平台时遇到HTTP状态码400，打开网络检查工具会直接跳转到源代码，一种说法是陷入无限debug中（每次返回的js代码不同），也无法添加断点，该站通过AJax请求更新页面时，提交的url携带两个随机生成的参数，无法通过后端的参数验证，暂时无法破解 一些某数逆向方法 使用fiddler进行请求拦截，进行调试 使用chrome的script监听器进行调试 本地搭建环境 验证码验证码，全称为Completely Automated Public Turing test to tell Computers and Humans Apart，即全自动区分计算机和人类的图灵测试（CAPTCHA）的缩写 顾名思义，验证码是一种反爬机制，识别验证码模拟登录一般有两个方法 肉眼识别 肉眼识别不是直接看浏览器图片，同样要爬取验证码图片到本地后再肉眼识别 借助第三方打码工具 云打码已经倒塌了 打码狗，性价比高，一次大概一两分钱 经过两天的满口芬芳，终于是明白了模拟普通中有关验证码的种种： 首先，验证码图片的url一般是携带随机参数的，但是这个随机数和前端反爬没有关系，只是用来从后端库中随机选一张验证码图片（虽然url有点怪） 其次，在get登录页面时，登录页面会自动向这个url发请求get一张验证码图片回来在前端显示，同时后端会记录下发起get请求的这个东西（浏览器或者是爬虫）究竟请求到了哪张验证码图片，所以当我们登录时后端才能进行比对 所以事实上，前端登录页面显示出来的的验证码和后端关系其实并不大，后端并不care某一个东西究竟对登录页面get了多少次，后端care的是对验证码图片的url究竟get了多少次，只不过每次get登录页面时会自动get一下验证码图片来显示在前端，所以这两次get是有先后顺序的 这个先后顺序非常重要，因为后端保存的永远是最后一次get验证码的记录，当我们在浏览器访问一个登录页面，我们会看到一个验证码A，而如果我们再去另一个窗口访问一下验证码图片的url后，我们会看到另一个验证码B，事实上，验证码B才是当前正确登录需要的验证码 另外，大部分网站都会在登录后进行跳转，一般在response.headers[‘Location’]中保存，对应的状态码一般是302，303，程序并不需要特殊处理页面重定位，程序发起登录请求成功会自动进行页面的重定位直到取到最后登录成功的页面 最后一点也是卡了我半天的点，我们知道登录时会有set-cookie字段设置cookie，所以程序一般要用requests.session()生成session对象发登录请求，session会自动保存response对象的set-cookie，这没什么，但是！一定要在get验证码图片时就使用session，不要先随便get一下等到发登录请求时再用session，否则你会寄的很惨 附几个练习模拟登录的网站： 南京大学计算机系本科支撑教育平台 考试酷 古诗文网 隐藏域隐藏域是一种常见的反爬手段，post请求提交的参数是由input表单域发起的，因此所有的参数都应该在网页中有对应的input文本框，但是有一些参数没有对应的input文本框，这些参数被隐藏了，这类问题称为隐藏域问题。 隐藏域对于用户是不可见的，一些网站在发生请求时会将隐藏域中的值作为参数传递，如果提交时缺省这些参数可能无法通过参数匹配，常见的解决方法时在源码中搜索对应隐藏域，解析获取其value值 例如古诗词网在登陆时会用到_VIEWSTATE、_VIEWSTATEGENERATOR两个隐藏域 封ip在单位时间内某ip访问次数超过阈值，服务器会禁止该ip的访问，返回403或错误信息等 最简单的处理方法，随便找个代理网站，随便拿一个ip贴过来，proxies&#x3D;{‘’} 搭个代理池，用的时候从里面拿一个ip 大致思路是写个爬虫，把各个免费代理网站中的ip和端口号爬下来，测试可以用的存到本地，用的时候随便取一个 测试http代理，该网站会返回发起请求的ip，用于测试代理是否有效 代理ip时效性强弱和本机物理位置有关，所以写个爬虫随时更新代理池还是很有必要的 经过自己的测试，大部分免费的ip代理延时都很大，会出现连接错误，天下没有免费的午餐 另外没有必要纠结于某一个ip或某一个网站代理，只要不是爬虫的bug，出错的直接丢掉就好不必纠结错误原因 一些提供有效的免费代理的网站： 玛卡巴卡 唔西迪西 依古比古-该网站提供https代理 ajax携带随机参数在爬取梨视频时，其中的视频url是动态加载的，定位ajax请求却发现参数中携带mrd随机数 实际上，在ajax请求中携带的随机参数多数不用于反爬目的，是前端用于欺骗浏览器或服务器的 某些代理服务器会忽略no-cache之类的标识对响应结果强行缓存（例如IE），如果url不改变的话浏览器可能不会真正向服务器发送请求而调用自己的缓存这样会导致后端的更新无法正确显示在前端，所以为保证每次请求都同服务器交互，前端会在url中携带一个随机数或一个时间戳，目的是使每次请求的url不同对于爬虫的模拟，需要在js源代码中找到对应的参数，找到其随机数的生成方式，直接在爬虫中模拟即可 总之，ajax请求携带的随机参数本意不在反爬（也就是说后端不会对数值进行比对，只会对随机数格式进行比对），但正确找到随机数的生成方式确实会对爬虫造成阻碍 伪url同样在爬取梨视频时，ajax请求返回的json数据中包含了视频的url，但直接访问该url得到404 仔细观察，json数据中的url和最终前端标签中的url不完全一致，也就是说梨视频还进行了一个url的转换，json数据中的url是一个伪url 这个就比较容易了，找到转换的规律进行替换就可以","path":"反反爬/","date":"08-01","excerpt":"","tags":[]},{"title":"本地图片","text":"","path":"本地图片/","date":"07-30","excerpt":"","tags":[]},{"title":"MD语法自查","text":"MarkDown语法自查1. 标题 2. 列表 3. 字体 4. 锚点 5. 代码块 6. 图片和超链接 7. 表格 8. 引用 标题主标题副标题一级标题二级标题六级标题列表有序列表： 首先 首先 首首先 其其次 最最后 其次 最后 其次 最后 无序列表： 首先 首先 其次 最后 其次 最后 字体斜体 粗体 粗斜体 花裙子 删除线 删除线 锚点定位到这里 代码块1234int main()&#123; return 0;&#125; 12def func(age): return age int a=5+9; 图片和超链接 csdn社区 https://www.csdn.net/ 表格 姓名 年龄 职业 张三 20000 医生 李四 60 警察叔叔 引用张三说： 阿门阿前一棵葡萄树 葡萄树说：这是不对的","path":"MD语法自查/","date":"07-29","excerpt":"","tags":[]},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","path":"hello-world/","date":"07-17","excerpt":"","tags":[]}],"categories":[],"tags":[]}